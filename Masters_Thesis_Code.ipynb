{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Paraphrase.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv0j5yFQ1Bmo"
      },
      "source": [
        "! pip install pandas\n",
        "! pip install torch\n",
        "! pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q17CaOhm6Q3l"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "projectFolder = \"./drive/My Drive/Bert/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFT54wV52BDF"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import  BertModel, BertTokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from torch.utils.data import Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_Hkph5m5s3a"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n3kKqRm2LcI"
      },
      "source": [
        "def read_and_shuffle(file):\n",
        "    df = pd.read_csv(file, delimiter='\\t')\n",
        "    # Random shuffle.\n",
        "    df.sample(frac=1)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oerGzXhG2Qjq"
      },
      "source": [
        "def get_train_and_val_split(df, splitRatio=0.8):\n",
        "    train=df.sample(frac=splitRatio,random_state=200)\n",
        "    val=df.drop(train.index)\n",
        "    print(\"Number of Training Samples: \", len(train))\n",
        "    print(\"Number of Validation Samples: \", len(val))\n",
        "    return(train, val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9naLmqgV2Sfl"
      },
      "source": [
        "def get_max_length(reviews):\n",
        "    return len(max(reviews, key=len))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruXknayR2VDa"
      },
      "source": [
        "def get_accuracy(logits, labels):\n",
        "    # get the index of the max value in the row.\n",
        "    predictedClass = logits.max(dim = 1)[1]\n",
        "\n",
        "    # get accuracy by averaging over entire batch.\n",
        "    acc = (predictedClass == labels).float().mean()\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vBprhKJ2ZVb"
      },
      "source": [
        "def trainFunc(net, loss_func, opti, train_loader, test_loader, config):\n",
        "    best_acc = 0\n",
        "    for ep in range(config[\"epochs\"]):\n",
        "        for it, (seq, attn_masks, labels) in enumerate(train_loader):\n",
        "            opti.zero_grad()\n",
        "            #seq, attn_masks, labels = seq.cuda(args.gpu), attn_masks.cuda(args.gpu), labels.cuda(args.gpu)\n",
        "            seq, attn_masks, labels = seq.to(device), attn_masks.to(device), labels.to(device)\n",
        "\n",
        "            logits = net(seq, attn_masks)\n",
        "            loss = loss_func(m(logits), labels)\n",
        "\n",
        "            loss.backward()\n",
        "            opti.step()\n",
        "            print(\"Iteration: \", it+1)\n",
        "\n",
        "            if (it + 1) % config[\"printEvery\"] == 0:\n",
        "                acc = get_accuracy(m(logits), labels)\n",
        "                if not os.path.exists(config[\"outputFolder\"]):\n",
        "                    os.makedirs(config[\"outputFolder\"])\n",
        "\n",
        "                # Since a single epoch could take well over hours, we regularly save the model even during evaluation of training accuracy.\n",
        "                torch.save(net.state_dict(), os.path.join(projectFolder, config[\"outputFolder\"], config[\"outputFileName\"]))\n",
        "                print(\"Iteration {} of epoch {} complete. Loss : {} Accuracy : {}\".format(it+1, ep+1, loss.item(), acc))\n",
        "                print(\"Saving at\", os.path.join(projectFolder, config[\"outputFolder\"], config[\"outputFileName\"]))\n",
        "\n",
        "        # perform validation at the end of an epoch.\n",
        "        val_acc, val_loss = evaluate(net, loss_func, val_loader, config)\n",
        "        print(\" Validation Accuracy : {}, Validation Loss : {}\".format(val_acc, val_loss))\n",
        "        if val_acc > best_acc:\n",
        "            print(\"Best validation accuracy improved from {} to {}, saving model...\".format(best_acc, val_acc))\n",
        "            best_acc = val_acc\n",
        "            torch.save(net.state_dict(), os.path.join(projectFolder, config[\"outputFolder\"], config[\"outputFileName\"] + \"_valTested_\" + str(best_acc)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSIptpqP2fRo"
      },
      "source": [
        "def evaluate(net, loss_func, dataloaderq, config):\n",
        "    net.eval()\n",
        "\n",
        "    mean_acc, mean_loss = 0, 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for seq, attn_masks, labels in dataloaderq:\n",
        "            #seq, attn_masks, labels = seq.cuda(args.gpu), attn_masks.cuda(args.gpu), labels.cuda(args.gpu)\n",
        "            seq, attn_masks, labels = seq.to(device), attn_masks.to(device), labels.to(device)\n",
        "\n",
        "            logits = net(seq, attn_masks)\n",
        "            mean_loss += loss_func(m(logits), labels)\n",
        "            mean_acc += get_accuracy(m(logits), labels)\n",
        "            print(\"Validation iteration\", count+1)\n",
        "            count += 1\n",
        "\n",
        "            '''\n",
        "            The entire validation set was around 0.1 million entries,\n",
        "            the validationFraction param controls what fraction of the shuffled\n",
        "            validation set you want to validate the results on.\n",
        "            '''\n",
        "            if count > config[\"validationFraction\"] * len(val_set):\n",
        "                break\n",
        "    return mean_acc / count, mean_loss / count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljqzMJFn2mV4"
      },
      "source": [
        "config = {\n",
        "    \"splitRatio\" : 0.8,\n",
        "    \"maxLength\" : 100,\n",
        "    \"printEvery\" : 100,\n",
        "    \"outputFolder\" : \"Models\",\n",
        "    \"outputFileName\" : \"ParaphraseClassifier.dat\",\n",
        "    \"threads\" : 4,\n",
        "    \"batchSize\" : 64,\n",
        "    \"validationFraction\" : 0.0005,\n",
        "    \"epochs\" : 2,\n",
        "    \"forceCPU\" : False\n",
        "    }\n",
        "if config[\"forceCPU\"]:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "config[\"device\"] = device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhyAAjcB2xqR"
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "    def __init__(self, num_classes, device, freeze_bert = True):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.device = device\n",
        "\n",
        "        if freeze_bert:\n",
        "            for p in self.bert_layer.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "        self.cls_layer = nn.Linear(768, num_classes)\n",
        "\n",
        "    def forward(self, seq, attn_masks):\n",
        "        '''\n",
        "        Inputs:\n",
        "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
        "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
        "        '''\n",
        "\n",
        "        #Feeding the input to BERT model to obtain contextualized representations\n",
        "        cont_reps, _ = self.bert_layer(seq, attention_mask = attn_masks)\n",
        "\n",
        "        #Obtaining the representation of [CLS] head\n",
        "        cls_rep = cont_reps[:, 0]\n",
        "\n",
        "        #Feeding cls_rep to the classifier layer\n",
        "        logits = self.cls_layer(cls_rep)\n",
        "\n",
        "        return logits.to(self.device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znUMPleM24mj"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "\n",
        "class AmazonReviewsDataset(Dataset):\n",
        "    def __init__(self, df, maxlen):\n",
        "        self.df = df\n",
        "        # A reset reindexes from 1 to len(df), the shuffled df frames are sparse.\n",
        "        self.df.reset_index(drop=True, inplace=True)\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def __len__(self):\n",
        "        return(len(self.df))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sent1 = self.df.loc[index, 'Sentence1']\n",
        "        sent2 = self.df.loc[index, 'Sentence2']\n",
        "\n",
        "        # Classes start from 0.\n",
        "       \tlabel = int(self.df.loc[index, 'Score'])\n",
        "\n",
        "        # Use BERT tokenizer since it needs to be able to match the tokens to the pre trained words.\n",
        "        token1 = self.tokenizer.tokenize(sent1)\n",
        "        token2 = self.tokenizer.tokenize(sent2)\n",
        "\n",
        "        # BERT inputs typically start with a '[CLS]' tag and end with a '[SEP]' tag. For\n",
        "        tokens = ['[CLS]'] + token1 + ['[SEP]'] + token2 + ['[SEP]']\n",
        "\n",
        "        if len(tokens) < self.maxlen:\n",
        "            # Add the ['PAD'] token\n",
        "            tokens = tokens + ['[PAD]' for item in range(self.maxlen-len(tokens))]\n",
        "        else:\n",
        "            # Truncate the tokens at maxLen - 1 and add a '[SEP]' tag.\n",
        "            tokens = tokens[:self.maxlen-1] + ['[SEP]']\n",
        "\n",
        "        # BERT tokenizer converts the string tokens to their respective IDs.\n",
        "        token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # Converting to pytorch tensors.\n",
        "        tokens_ids_tensor = torch.tensor(token_ids)\n",
        "\n",
        "        # Masks place a 1 if token != PAD else a 0.\n",
        "        attn_mask = (tokens_ids_tensor != 0).long()\n",
        "\n",
        "        return tokens_ids_tensor, attn_mask, label\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6qMODHX3MQ0"
      },
      "source": [
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "print(\"Configuration is: \", config)\n",
        "# Read and shuffle input data.\n",
        "df = read_and_shuffle(os.path.join(projectFolder, \"PARAPHRASE-DATASET/datap.csv\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc--gWsRVPn3"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYyvxXRR3ceK"
      },
      "source": [
        "num_classes = df['Score'].nunique()\n",
        "print(\"Number of Target Output Classes:\", num_classes)\n",
        "totalDatasetSize = len(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P6nDjzD3hCh"
      },
      "source": [
        "# Group by the column Score. This helps you get distribution of the Review Scores.\n",
        "symbols = df.groupby('Score')\n",
        "\n",
        "scores_dist = []\n",
        "for i in range(num_classes):\n",
        "    scores_dist.append(len(symbols.groups[i])/totalDatasetSize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nmoAHec3mnP"
      },
      "source": [
        "train, val = get_train_and_val_split(df, config[\"splitRatio\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKdvSrplWUpH"
      },
      "source": [
        "val.to_csv(os.path.join(projectFolder, \"PARAPHRASE-DATASET/Validations.csv\"))\n",
        "train.to_csv(os.path.join(projectFolder, \"PARAPHRASE-DATASET/Train.csv\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PQMMnpz3ptw"
      },
      "source": [
        "# You can set the length to the true max length from the dataset, I have reduced it for the sake of memory and quicker training.\n",
        "#T = get_max_length(reviews)\n",
        "T = config[\"maxLength\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA2kwsot3tkz"
      },
      "source": [
        "train_set = AmazonReviewsDataset(train, T)\n",
        "val_set = AmazonReviewsDataset(val, T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MbfDj7w31p-"
      },
      "source": [
        "train_loader = DataLoader(train_set, batch_size = config[\"batchSize\"], num_workers = config[\"threads\"])\n",
        "val_loader = DataLoader(val_set, batch_size = config[\"batchSize\"], num_workers = config[\"threads\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0gR6VMY39FG"
      },
      "source": [
        "# We are unfreezing the BERT layers so as to be able to fine tune and save a new BERT model that is specific to the Sizeable food reviews dataset.\n",
        "\n",
        "net = SentimentClassifier(num_classes, config[\"device\"], freeze_bert=False)\n",
        "net.to(config[\"device\"])\n",
        "weights = torch.tensor(scores_dist).to(config[\"device\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP5uo4sf4MxK"
      },
      "source": [
        "# Setting the Loss function and Optimizer.\n",
        "loss_func = nn.NLLLoss(weight=weights)\n",
        "opti = optim.Adam(net.parameters(), lr = 2e-5)\n",
        "m = nn.LogSoftmax(dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfvnHnNW4SRZ"
      },
      "source": [
        "torch.cuda.set_device(0)\n",
        "trainFunc(net, loss_func, opti, train_loader, val_loader, config)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}